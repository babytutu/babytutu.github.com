import{_ as e,c as s,a2 as l,o as p}from"./chunks/framework.BPuE4Feg.js";const o="/assets/chatbox.SwscHWVC.png",b=JSON.parse('{"title":"本地部署 deepseek-r1","description":"","frontmatter":{},"headers":[],"relativePath":"tools/deepseek.md","filePath":"tools/deepseek.md"}'),r={name:"tools/deepseek.md"};function n(t,a,i,d,c,h){return p(),s("div",null,a[0]||(a[0]=[l('<h1 id="本地部署-deepseek-r1" tabindex="-1">本地部署 deepseek-r1 <a class="header-anchor" href="#本地部署-deepseek-r1" aria-label="Permalink to &quot;本地部署 deepseek-r1&quot;">​</a></h1><p>使用 Ollama 快速部署 deepseek-r1 到本地</p><h2 id="下载-ollama" tabindex="-1">下载 Ollama <a class="header-anchor" href="#下载-ollama" aria-label="Permalink to &quot;下载 Ollama&quot;">​</a></h2><p>官方下载地址 <a href="https://ollama.com/download" target="_blank" rel="noreferrer">https://ollama.com/download</a></p><p>下载对应的大模型，最热门的就是 deepseek-r1</p><p><a href="https://ollama.com/library/deepseek-r1" target="_blank" rel="noreferrer">https://ollama.com/library/deepseek-r1</a></p><h2 id="安装" tabindex="-1">安装 <a class="header-anchor" href="#安装" aria-label="Permalink to &quot;安装&quot;">​</a></h2><p>安装 Ollama 后，选择对应的模型，版本分别有 1.5b/7b/8b/14b/32b/70b/671b</p><p>本地安装，需要根据电脑配置选择对应版本，16G 内存选择 8b 以下</p><p>打开终端，验证 ollama 已成功安装</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki one-dark-pro vp-code" tabindex="0"><code><span class="line"><span style="color:#61AFEF;">ollama</span><span style="color:#D19A66;"> -v</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>我本地安装后显示版本</p><p>ollama version is 0.5.10</p><p>确认安装完成后，可启动对应版本模型，如 1.5b 版本，如本地未下载，会自动下载</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki one-dark-pro vp-code" tabindex="0"><code><span class="line"><span style="color:#61AFEF;">ollama</span><span style="color:#98C379;"> run</span><span style="color:#98C379;"> deepseek-r1:1.5b</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>1.5b 版本大小为 1.1GB，下载完成后，会进入聊天模式</p><div class="language-sh line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">sh</span><pre class="shiki one-dark-pro vp-code" tabindex="0"><code><span class="line"><span style="color:#ABB2BF;">&gt;&gt;&gt; </span><span style="color:#61AFEF;">Send</span><span style="color:#98C379;"> a</span><span style="color:#98C379;"> message</span><span style="color:#ABB2BF;"> (/? </span><span style="color:#98C379;">for</span><span style="color:#98C379;"> help</span><span style="color:#ABB2BF;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br></div></div><p>此时和直接和它聊天，但大模型不支持联网，无法获取实时信息，且不太聪明，只能说能用。</p><h3 id="ollama-常用命令" tabindex="-1">ollama 常用命令 <a class="header-anchor" href="#ollama-常用命令" aria-label="Permalink to &quot;ollama 常用命令&quot;">​</a></h3><ul><li>run xxx 运行模型 xxx</li><li>list 展示所有模型</li><li>ps 展示资源占用</li><li>show xxx 查看模型 xxx 信息</li><li>rm xxx 删除模型 xxx</li></ul><h2 id="接入可视化界面" tabindex="-1">接入可视化界面 <a class="header-anchor" href="#接入可视化界面" aria-label="Permalink to &quot;接入可视化界面&quot;">​</a></h2><p>Chatbox AI <a href="https://chatboxai.app/zh" target="_blank" rel="noreferrer">https://chatboxai.app/zh</a></p><p>直接下载安装包，经过简单配置就可以和本地的 deepseek 开始聊天。</p><p>需要先本地运行 ollama 和对应模型</p><p><img src="'+o+'" alt="设置"></p>',25)]))}const u=e(r,[["render",n]]);export{b as __pageData,u as default};
